[
["entering-and-cleaning-data-2.html", "Chapter 6 Entering and cleaning data #2 6.1 Joining datasets 6.2 Tidy data 6.3 Gathering 6.4 In-course exercise", " Chapter 6 Entering and cleaning data #2 Download a pdf of the lecture slides covering this topic. 6.1 Joining datasets So far, you have only worked with a single data source at a time. When you work on your own projects, however, you typically will need to merge together two or more datasets to create the a data frame to answer your research question. For example, for air pollution epidemiology, you will often have to join several datasets: Health outcome data (e.g., number of deaths per day) Air pollution concentrations Weather measurements (since weather can be a confounder) Demographic data The dplyr package has a family of different functions to join two dataframes together, the *_join family of functions. All combine two dataframes, which I’ll call x and y here. The functions include: inner_join(x, y): Keep only rows where there are observations in both x and y. left_join(x, y): Keep all rows from x, whether they have a match in y or not. right_join(x, y): Keep all rows from y, whether they have a match in x or not. full_join(x, y): Keep all rows from both x and y, whether they have a match in the other dataset or not. In the examples, I’ll use two datasets, x and y. Both datasets include the column course. The other column in x is grade, while the other column in y is day. Observations exist for courses x and y in both datasets, but for w and z in only one dataset. x &lt;- data.frame(course = c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), grade = c(90, 82, 78)) y &lt;- data.frame(course = c(&quot;w&quot;, &quot;x&quot;, &quot;y&quot;), day = c(&quot;Tues&quot;, &quot;Mon / Fri&quot;, &quot;Tue&quot;)) Here is what these two example datasets look like: x ## course grade ## 1 x 90 ## 2 y 82 ## 3 z 78 y ## course day ## 1 w Tues ## 2 x Mon / Fri ## 3 y Tue With inner_join, you’ll only get the observations that show up in both datasets. That means you’ll lose data on z (only in the first dataset) and w (only in the second dataset). inner_join(x, y) ## Joining, by = &quot;course&quot; ## course grade day ## 1 x 90 Mon / Fri ## 2 y 82 Tue With left_join, you’ll keep everything in x (the “left” dataset), but not keep things in y that don’t match something in x. That means that, here, you’ll lose w: left_join(x, y) ## Joining, by = &quot;course&quot; ## course grade day ## 1 x 90 Mon / Fri ## 2 y 82 Tue ## 3 z 78 &lt;NA&gt; right_join is the opposite: right_join(x, y) ## Joining, by = &quot;course&quot; ## course grade day ## 1 w NA Tues ## 2 x 90 Mon / Fri ## 3 y 82 Tue full_join keeps everything from both datasets: full_join(x, y) ## Joining, by = &quot;course&quot; ## course grade day ## 1 x 90 Mon / Fri ## 2 y 82 Tue ## 3 z 78 &lt;NA&gt; ## 4 w NA Tues 6.2 Tidy data All of the material in this section comes directly from Hadley Wickham’s paper on tidy data. You will need to read this paper to prepare for the quiz on this section. Getting your data into a “tidy” format makes it easier to model and plot. By taking the time to tidy your data at the start of an analysis, you will save yourself time, and make it easier to plan out later steps. Characteristics of tidy data are: Each variable forms a column. Each observation forms a row. Each type of observational unit forms a table. Here are five common problems that Hadley Wickham has identified that keep data from being tidy: Column headers are values, not variable names. Multiple variables are stored in one column. Variables are stored in both rows and columns. Multiple types of observational units are stored in the same table. A single observational unit is stored in multiple tables. Here are examples (again, from Hadley Wickham’s paper on tidy data, which is required reading for this week of the course) of each of these problems. Column headers are values, not variable names. Solution: Multiple variables are stored in one column. Solution: Variables are stored in both rows and columns. Solution: Multiple types of observational units are stored in the same table. Solution: A single observational unit is stored in multiple tables. Example: exposure and outcome data stored in different files: File 1: Daily mortality counts File 2: Daily air pollution measurements 6.3 Gathering There are two functions from the tidyr package (another member of the tidyverse) that you can use to change between wide and long data: gather and spread. Here is a description of these two functions: gather: Take several columns and gather them into two columns, one with the former column names, and one with the former cell values. spread: Take two columns and spread them into multiple columns. Column names for the new columns will come from one of the two original columns, while cell values will come from the other of the original columns. The following examples are from tidyr help files and show the effects of gathering and spreading a dataset. Here is some simulated wide data: wide_stocks[1:3, ] ## time X Y Z ## 1 2009-01-01 0.73739022 1.280170 -1.088980 ## 2 2009-01-02 -1.09290634 -1.630775 -4.736517 ## 3 2009-01-03 0.02153739 2.795653 2.924699 In the wide_stocks dataset, there are separate columns for three different stocks (X, Y, and Z). Each cell gives the value for a certain stock on a certain day. This data isn’t “tidy”, because the identify of the stock (X, Y, or Z) is a variable, and you’ll probably want to include it as a variable in modeling. wide_stocks[1:3, ] ## time X Y Z ## 1 2009-01-01 0.73739022 1.280170 -1.088980 ## 2 2009-01-02 -1.09290634 -1.630775 -4.736517 ## 3 2009-01-03 0.02153739 2.795653 2.924699 If you want to convert the dataframe to have all stock values in a single column, you can use gather to convert wide data to long data: long_stocks &lt;- gather(wide_stocks, key = stock, value = price, -time) long_stocks[1:5, ] ## time stock price ## 1 2009-01-01 X 0.73739022 ## 2 2009-01-02 X -1.09290634 ## 3 2009-01-03 X 0.02153739 ## 4 2009-01-04 X -1.76438096 ## 5 2009-01-05 X 1.19878982 In this “long” dataframe, there is now one column that gives the identify of the stock (stock) and another column that gives the price of that stock that day (price): long_stocks[1:5, ] ## time stock price ## 1 2009-01-01 X 0.73739022 ## 2 2009-01-02 X -1.09290634 ## 3 2009-01-03 X 0.02153739 ## 4 2009-01-04 X -1.76438096 ## 5 2009-01-05 X 1.19878982 The format for a gather call is: ## Generic code new_df &lt;- gather(old_df, key = [name of column with old column names], value = [name of column with cell values], - [name of column(s) you want to exclude from gather]) Three important notes: Everything is gathered into one of two columns – one column with the old column names, and one column with the old cell values With the key and value arguments, you are just providing column names for the two columns that everything’s gathered into. If there is a column you don’t want to gather (date in the example), use - to exclude it in the gather call. Notice how easy it is, now that the data is gathered, to use stock for aesthetics of faceting in a ggplot2 call: ggplot(long_stocks, aes(x = time, y = price)) + geom_line() + facet_grid(. ~ stock) If you have data in a “long” format and would like to spread it out, you can use spread to do that: stocks &lt;- spread(long_stocks, key = stock, value = price) stocks[1:5, ] ## time X Y Z ## 1 2009-01-01 0.73739022 1.2801696 -1.088980 ## 2 2009-01-02 -1.09290634 -1.6307746 -4.736517 ## 3 2009-01-03 0.02153739 2.7956532 2.924699 ## 4 2009-01-04 -1.76438096 -0.2076843 4.685565 ## 5 2009-01-05 1.19878982 0.6577886 4.270217 Notice that this reverses the action of gather. “Spread” data is typically not tidy, so you often won’t want to use spread when you are preparing data for analysis. However, spread can be very helpful in creating clean tables for final reports and presentations. For example, if you wanted to create a table with means and standard deviations for each of the three stocks, you could use spread to rearrange the final summary to create an attractive table. stock_summary &lt;- long_stocks %&gt;% group_by(stock) %&gt;% summarize(N = n(), mean = mean(price), sd = sd(price)) stock_summary ## # A tibble: 3 x 4 ## stock N mean sd ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 X 10 0.401 1.61 ## 2 Y 10 0.495 1.63 ## 3 Z 10 1.03 3.92 stock_summary %&gt;% mutate(&quot;Mean (Std.dev.)&quot; = paste0(round(mean, 2), &quot; (&quot;, round(sd, 2), &quot;)&quot;)) %&gt;% select(- mean, - sd) %&gt;% gather(key = &quot;Statistic&quot;, value = &quot;Value&quot;, -stock) %&gt;% spread(key = stock, value = Value) %&gt;% knitr::kable() Statistic X Y Z Mean (Std.dev.) 0.4 (1.61) 0.49 (1.63) 1.03 (3.92) N 10 10 10 6.4 In-course exercise For today’s exercise, we’ll be using the following three datasets (click on the file name to access the correct file for today’s class for each dataset): File name Description country_timeseries.csv Ebola cases by country for the 2014 outbreak mexico_exposure.csv and mexico_deaths.csv Daily death counts and environmental measurements for Mexico City, Mexico, for 2008 measles_data/ Number of cases of measles in CA since end of Dec. 2014 Note that you likely have already downloaded all the files in the measles_data folder, since we used them in an earlier in-course exercise. If so, there is no need to re-download those files. Here are the sources for this data: country_timeseries.csv : Caitlin Rivers’ Ebola repository (Caitlin originally collected this data from the WHO and WHO Situation reports) mexico_exposure.csv and mexico_deaths.csv : one of Hadley Wickham’s GitHub repos (Hadley got the data originally from the Secretaria de Salud of Mexico’s website, although it appears the link is now broken. I separated the data into two dataframes so students could practice merging.) measles_data/: one of scarpino’s GitHub repos (Data originally from pdfs from the California Department of Public Health) If you want to use these data further, you should go back and pull them from their original sources. They are here only for use in R code examples for this course. Here are some of the packages you will need for this exercise: library(dplyr) library(gridExtra) library(ggthemes) 6.4.1 Designing tidy data Check out the country_timeseries.csv file on Ebola for this week’s example data. Talk with your partner and decide what changes you would need to make to this dataset to turn it into a “tidy” dataset, in particular which of the five common “untidy” problems the data currently has and why. Do the same for the data on daily mortality and daily weather in Mexico. Do the same for the set of files with measles data. 6.4.2 Easier data wrangling Use read_csv to read the Mexico data (exposure and mortality) directly from GitHub into your R session. Call the dataframes mex_deaths and mex_exp. Are there any values of the day column in mex_deaths that is not present in the day column of mex_exp? How about vice-versa? (Hint: There are a few ways you could check this. One is to try filtering down to just rows in one dataframe where the day values are not present in the day values from the other dataframe. The %in% logical vector may be useful.) Merge the two datasets together to create the dataframe mexico. Exclude all columns except the outcome (deaths), day, and mean temperature. Convert the day to a Date class. If you did not already, try combining all the steps in the previous task into one “chained” pipeline of code using the pipe operator, %&gt;%. Use this new dataframe to plot deaths by date in Mexico using ggplot2. The final plot should look like this: 6.4.2.1 Example R code Use read_csv to read the mexico data (exposure and mortality) directly from GitHub into your R session. Call the dataframes mex_deaths and mex_exp: deaths_url &lt;- paste0(&quot;https://github.com/geanders/RProgrammingForResearch/&quot;, &quot;raw/master/data/mexico_deaths.csv&quot;) mex_deaths &lt;- read_csv(deaths_url) head(mex_deaths) ## # A tibble: 6 x 2 ## day deaths ## &lt;chr&gt; &lt;int&gt; ## 1 1/1/08 296 ## 2 1/2/08 274 ## 3 1/3/08 339 ## 4 1/4/08 300 ## 5 1/5/08 327 ## 6 1/6/08 332 exposure_url &lt;- paste0(&quot;https://github.com/geanders/RProgrammingForResearch/&quot;, &quot;raw/master/data/mexico_exposure.csv&quot;) mex_exp &lt;- read_csv(exposure_url) head(mex_exp) ## # A tibble: 6 x 14 ## day temp_min temp_max temp_mean humidity wind NO NO2 NOX ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1/1/08 7.80 17.8 11.8 53.5 2.66 0.00925 0.0187 0.0278 ## 2 1/2/08 2.60 9.80 6.64 61.7 3.35 0.00542 0.0187 0.0241 ## 3 1/3/08 1.10 15.6 7.04 59.9 1.89 0.0160 0.0381 0.0540 ## 4 1/4/08 3.10 20.6 10.9 57.5 1.20 0.0408 0.0584 0.0993 ## 5 1/5/08 6.00 21.3 13.4 45.7 0.988 0.0469 0.0602 0.107 ## 6 1/6/08 7.20 22.1 14.3 40.8 0.854 0.0286 0.0510 0.0795 ## # ... with 5 more variables: O3 &lt;dbl&gt;, CO &lt;dbl&gt;, SO2 &lt;dbl&gt;, PM10 &lt;dbl&gt;, ## # PM25 &lt;dbl&gt; Check if there are any values of the day column in mex_deaths that are not present in the day column of mex_exp and vice-versa. mex_deaths %&gt;% filter(!(day %in% mex_exp$day)) ## # A tibble: 0 x 2 ## # ... with 2 variables: day &lt;chr&gt;, deaths &lt;int&gt; mex_exp %&gt;% filter(!(day %in% mex_deaths$day)) ## # A tibble: 0 x 14 ## # ... with 14 variables: day &lt;chr&gt;, temp_min &lt;dbl&gt;, temp_max &lt;dbl&gt;, ## # temp_mean &lt;dbl&gt;, humidity &lt;dbl&gt;, wind &lt;dbl&gt;, NO &lt;dbl&gt;, NO2 &lt;dbl&gt;, ## # NOX &lt;dbl&gt;, O3 &lt;dbl&gt;, CO &lt;dbl&gt;, SO2 &lt;dbl&gt;, PM10 &lt;dbl&gt;, PM25 &lt;dbl&gt; One important note is that, when you’re doing this check, you do not want to overwrite your original dataframe, so be sure that you do not reassign this output to mex_deaths or mex_exp. An even quicker way to do check this is to create a logical vector that checks this and use sum to add up the values in the logical vector. If the sum is zero, that tells you that the logical check is never true, so there are no cases where there is a day value in one dataframe that is not also in the other dataframe. sum(!(mex_deaths$day %in% mex_exp$day)) ## [1] 0 sum(!(mex_exp$day %in% mex_deaths$day)) ## [1] 0 Merge the two datasets together to create the dataframe mexico. Exclude all columns except the outcome (deaths), date, and mean temperature. mexico &lt;- full_join(mex_deaths, mex_exp, by = &quot;day&quot;) mexico &lt;- select(mexico, day, deaths, temp_mean) Convert the date to a date class. library(lubridate) ## For parsing dates mexico &lt;- mutate(mexico, day = mdy(day)) Try combining all the steps in the previous task into one “chained” command: mexico &lt;- full_join(mex_deaths, mex_exp, by = &quot;day&quot;) %&gt;% select(day, deaths, temp_mean) %&gt;% mutate(day = mdy(day)) head(mexico) ## # A tibble: 6 x 3 ## day deaths temp_mean ## &lt;date&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2008-01-01 296 11.8 ## 2 2008-01-02 274 6.64 ## 3 2008-01-03 339 7.04 ## 4 2008-01-04 300 10.9 ## 5 2008-01-05 327 13.4 ## 6 2008-01-06 332 14.3 Note that, in this case, all the values of day in mex_deaths have one and only one matching value in mex_exp, and vice-versa. Because of this, we would have gotten the same mexico dataframe if we’d used inner_join, left_join or right_join instead of full_join. The differences between these *_join functions come into play when you have some values of your matching column that aren’t in both of the dataframes you’re joining. Use this new dataframe to plot deaths by date using ggplot: ggplot(data = mexico) + geom_point(mapping = aes(x = day, y = deaths), size = 1.5, alpha = 0.5) + labs(x = &quot;Date in 2008&quot;, y = &quot;# of deaths&quot;) + ggtitle(&quot;Deaths by date&quot;) + theme_few() 6.4.3 More extensive data wrangling Read the Ebola data directly from GitHub into your R session. Call the dataframe ebola. Use dplyr functions to create a tidy dataset. First, change it from “wide” data to “long” data. Name the new column with the key variable and the new column with the values count. The first few lines of the “long” version of the dataset should look like this: ## # A tibble: 6 x 4 ## Date Day variable count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 1/5/2015 289 Cases_Guinea 2776 ## 2 1/4/2015 288 Cases_Guinea 2775 ## 3 1/3/2015 287 Cases_Guinea 2769 ## 4 1/2/2015 286 Cases_Guinea NA ## 5 12/31/2014 284 Cases_Guinea 2730 ## 6 12/28/2014 281 Cases_Guinea 2706 Convert the Date column to a Date class. Use the separate function to separate the variable column into two columns, type (“Cases” or “Deaths”) and country (“Guinea”, “Liberia”, etc.). At this point, the data should look like this: ## # A tibble: 6 x 5 ## Date Day type country count ## &lt;date&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2015-01-05 289 Cases Guinea 2776 ## 2 2015-01-04 288 Cases Guinea 2775 ## 3 2015-01-03 287 Cases Guinea 2769 ## 4 2015-01-02 286 Cases Guinea NA ## 5 2014-12-31 284 Cases Guinea 2730 ## 6 2014-12-28 281 Cases Guinea 2706 Use the spread function to convert the data so you have separate columns for the two variables of numbers of Cases and Deaths. At this point, the dataframe should look like this: ## # A tibble: 6 x 5 ## Date Day country Cases Deaths ## &lt;date&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 2014-03-22 0 Guinea 49 29 ## 2 2014-03-22 0 Liberia NA NA ## 3 2014-03-22 0 Mali NA NA ## 4 2014-03-22 0 Nigeria NA NA ## 5 2014-03-22 0 Senegal NA NA ## 6 2014-03-22 0 SierraLeone NA NA Remove any observations where counts of both cases and deaths are missing for that country on that date. Now that your data is tidy, create one plot showing Ebola cases by date, faceted by country, and one showing Ebola deaths by date, also faceted by country. Try using the option scales = &quot;free_y&quot; in the facet_wrap function and see how that changes these graphs. Discuss with your group the advantages and disadvantages of using this option when creating these small multiple plots. The plots should look something like this (if you’re using the scales = &quot;free_y&quot; option): Based on these plots, what would your next questions be about this data before you used it for an analysis? Can you put all of the steps of this cleaning process into just a few “chained” code pipelines using %&gt;%? If you have extra time (super-challenge!): There is a function called fct_reorder in the forcats package that can be used to reorder the levels of a factor in a dataframe based on another column in the same dataframe. This function can be very useful for using a meaningful order when plotting. We’ll cover the forcats package in a later class, but today check out the help file for fct_reorder and see if you can figure out how to use it to reorder the small multiple plots in order of the maximum number of cases or deaths (for the two plots respectively) in each country. You’ll be able to do this by changing the code in facet_wrap from ~ country to ~ fct_reorder(country, ...), but with the ... replaced with certain arguments. If you’re getting stuck, try running the examples in the fct_reorder helpfile to get a feel for how this function can be used when plotting. The plots will look something like this: 6.4.3.1 Example R code Read the data in using read_csv. ebola_url &lt;- paste0(&quot;https://github.com/geanders/RProgrammingForResearch/&quot;, &quot;raw/master/data/country_timeseries.csv&quot;) ebola &lt;- read_csv(ebola_url) head(ebola) ## # A tibble: 6 x 18 ## Date Day Cases_Guinea Cases_Liberia Cases_SierraLeo… Cases_Nigeria ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1/5/2015 289 2776 NA 10030 NA ## 2 1/4/2015 288 2775 NA 9780 NA ## 3 1/3/2015 287 2769 8166 9722 NA ## 4 1/2/2015 286 NA 8157 NA NA ## 5 12/31/2… 284 2730 8115 9633 NA ## 6 12/28/2… 281 2706 8018 9446 NA ## # ... with 12 more variables: Cases_Senegal &lt;int&gt;, ## # Cases_UnitedStates &lt;int&gt;, Cases_Spain &lt;int&gt;, Cases_Mali &lt;int&gt;, ## # Deaths_Guinea &lt;int&gt;, Deaths_Liberia &lt;int&gt;, Deaths_SierraLeone &lt;int&gt;, ## # Deaths_Nigeria &lt;int&gt;, Deaths_Senegal &lt;int&gt;, Deaths_UnitedStates &lt;int&gt;, ## # Deaths_Spain &lt;int&gt;, Deaths_Mali &lt;int&gt; Change the data to long data using the gather() function from dplyr: ebola &lt;- ebola %&gt;% gather(key = variable, value = count, -Date, -Day) head(ebola) ## # A tibble: 6 x 4 ## Date Day variable count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 1/5/2015 289 Cases_Guinea 2776 ## 2 1/4/2015 288 Cases_Guinea 2775 ## 3 1/3/2015 287 Cases_Guinea 2769 ## 4 1/2/2015 286 Cases_Guinea NA ## 5 12/31/2014 284 Cases_Guinea 2730 ## 6 12/28/2014 281 Cases_Guinea 2706 Convert Date to a date class: ebola &lt;- ebola %&gt;% mutate(Date = mdy(Date)) head(ebola) ## # A tibble: 6 x 4 ## Date Day variable count ## &lt;date&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2015-01-05 289 Cases_Guinea 2776 ## 2 2015-01-04 288 Cases_Guinea 2775 ## 3 2015-01-03 287 Cases_Guinea 2769 ## 4 2015-01-02 286 Cases_Guinea NA ## 5 2014-12-31 284 Cases_Guinea 2730 ## 6 2014-12-28 281 Cases_Guinea 2706 Split variable into type and country: ebola &lt;- ebola %&gt;% separate(variable, c(&quot;type&quot;, &quot;country&quot;), sep = &quot;_&quot;) head(ebola) ## # A tibble: 6 x 5 ## Date Day type country count ## &lt;date&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2015-01-05 289 Cases Guinea 2776 ## 2 2015-01-04 288 Cases Guinea 2775 ## 3 2015-01-03 287 Cases Guinea 2769 ## 4 2015-01-02 286 Cases Guinea NA ## 5 2014-12-31 284 Cases Guinea 2730 ## 6 2014-12-28 281 Cases Guinea 2706 Convert the data so you have separate columns for the two variables of numbers of Cases and Deaths: ebola &lt;- spread(ebola, key = type, value = count) head(ebola) ## # A tibble: 6 x 5 ## Date Day country Cases Deaths ## &lt;date&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 2014-03-22 0 Guinea 49 29 ## 2 2014-03-22 0 Liberia NA NA ## 3 2014-03-22 0 Mali NA NA ## 4 2014-03-22 0 Nigeria NA NA ## 5 2014-03-22 0 Senegal NA NA ## 6 2014-03-22 0 SierraLeone NA NA Remove any observations where counts of cases or deaths are missing for that country: ebola &lt;- filter(ebola, !is.na(Cases) &amp; !is.na(Deaths)) head(ebola) ## # A tibble: 6 x 5 ## Date Day country Cases Deaths ## &lt;date&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 2014-03-22 0 Guinea 49 29 ## 2 2014-03-24 2 Guinea 86 59 ## 3 2014-03-25 3 Guinea 86 60 ## 4 2014-03-26 4 Guinea 86 62 ## 5 2014-03-27 5 Guinea 103 66 ## 6 2014-03-27 5 Liberia 8 6 Now that your data is tidy, create one plot showing ebola cases by date, faceted by country, and one showing ebola deaths by date, also faceted by country: ggplot(ebola, aes(x = Date, y = Cases)) + geom_line() + facet_wrap(~ country, ncol = 4) + theme_classic() ggplot(ebola, aes(x = Date, y = Deaths)) + geom_line() + facet_wrap(~ country, ncol = 4) + theme_classic() Try using the option scales = &quot;free_y&quot; in the facet_wrap() function (in the gridExtra package) and see how that changes these graphs: ggplot(ebola, aes(x = Date, y = Cases)) + geom_line() + facet_wrap(~ country, ncol = 4, scales = &quot;free_y&quot;) + theme_classic() ggplot(ebola, aes(x = Date, y = Deaths)) + geom_line() + facet_wrap(~ country, ncol = 4, scales = &quot;free_y&quot;) + theme_classic() Put all of the steps of this cleaning process into just a few “chaining” calls. ebola &lt;- read_csv(ebola_url) %&gt;% gather(variable, count, -Date, -Day) %&gt;% mutate(Date = mdy(Date)) %&gt;% separate(variable, c(&quot;type&quot;, &quot;country&quot;), sep = &quot;_&quot;) %&gt;% spread(type, count) %&gt;% filter(!is.na(Cases) &amp; !is.na(Deaths)) ggplot(ebola, aes(x = Date, y = Cases)) + geom_line() + facet_wrap(~ country, ncol = 4) + theme_classic() ggplot(ebola, aes(x = Date, y = Deaths)) + geom_line() + facet_wrap(~ country, ncol = 4) + theme_classic() Use the fct_reorder function inside the facet_wrap function call to reorder the small-multiple graphs. library(forcats) ggplot(ebola, aes(x = Date, y = Cases)) + geom_line() + facet_wrap(~ fct_reorder(country, Cases, fun = max, .desc = TRUE), ncol = 4) + theme_classic() ggplot(ebola, aes(x = Date, y = Deaths)) + geom_line() + facet_wrap(~ fct_reorder(country, Deaths, fun = max, .desc = TRUE), ncol = 4) + theme_classic() 6.4.4 Tidying VADeaths data R comes with a dataset called VADeaths that gives death rates per 1,000 people in Virginia in 1940 by age, sex, and rural / urban. Use data(&quot;VADeaths&quot;) to load this data. Make sure you understand what each column and row is showing – use the helpfile (?VADeaths) if you need. Go through the three characteristics of tidy data and the five common problems in untidy data that we talked about in class. Sketch out (you’re welcome to use the whiteboards) what a tidy version of this data would look like. Open a new R script file. Write R code to transform this dataset into a tidy dataset. Try using a pipe chain, with %&gt;% and tidyverse functions, to clean the data. Use the tidy data to create the following graph: There is no example R code for this – try to figure out the code yourselves. We will go over a solution in class. You may find the RStudio Data Wrangling cheatsheet helpful for remembering which tidyverse functions do what. 6.4.5 Exploring Fatality Analysis Reporting System (FARS) data Explore the interactive visualization at http://metrocosm.com/10-years-of-traffic-accidents-mapped.html. This was created by Max Galka using this dataset. Go to FARS web page. We want to get the raw data on fatal accidents. Navigate this page to figure out how you can get this raw data for the whole county for 2016 (hint: you’ll need to access the raw data using FTP, and you may have more success with some web browsers, like Chrome, than others). Save 2016 “National” data (csv format) to your computer. What is the structure of how this data is saved (e.g., directory structure, file structure)? On the FARS web page, find the documentation describing this raw data. Look through both this documentation (2016 Crash Report Sampling System (CRSS):Analytical User’s Manual) and the raw files you downloaded to figure out what information is included in the data. Read the accident.csv file for 2016 into R (this is one of the files you’ll get if you download the raw data for 2016). Use the documentation to figure out what each column represents. Discuss what steps you would need to take to create the following plot. To start, don’t write any code, just develop a plan. Talk about what the dataset should look like right before you create the plot and what functions you could use to get the data from its current format to that format. (Hint: Functions from the lubridate package will be very helpful, including yday and wday). Discuss which of the variables in this dataset could be used to merge the dataset with other appropriate data, either other datasets in the FARS raw data, or outside datasets. Try to write the code to create this plot. This will include some code for cleaning the data and some code for plotting. I will add one example answer after class, but I’d like you to try to figure it out yourselves first. "]
]
